\documentclass{article}

\usepackage{fontspec}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{amssymb}
\usepackage{listings}
\lstset{%
  escapeinside={(*}{*)}
  }

\usepackage{mathtools}
\usepackage{mathpartir}
\usepackage{xfrac}

\newcommand{\ty}[1]{\texttt{#1}}
\newcommand{\set}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\undef}{\oslash}
\newcommand{\quasiconst}{\twoheadrightarrow}
\DeclareMathOperator\dom{dom}
\newcommand{\orthsum}{\oplus^\bot}

\newcommand{\Γ}{\Gamma}
\newcommand{\τ}{\tau}

\title{Typing of records in nix}
\author{Théophane Hufschmitt}
\date{}

\begin{document}

\maketitle{}

\section{Static labels}
\subsection{Typing in a CBV setting}
The typing of records in a CBV language is already given (in absence of
polymorphism) by the formalism given in part 4.5 of~\cite{Cas15} (which itself
is the reformulation of the formalism presented by Alain Frisch in its Phd
Thesis − see~\cite{Fri04}).

In the original formalism, records (resp.\ record types) are interpreted as
\emph{quasi-constant} functions from \ty{string} to $\textbf{Values} \cup
\undef$ (resp.\ from \ty{string} to $\textbf{Types} \cup \undef$), where
\begin{itemize}
  \item A \emph{quasi-constant} function from \set{L} to \set{Z} is a
    function $r: \set{L} \rightarrow \set{Z}$ which is constant to an element
    $z \in \set{Z}$, except for a finite set $\dom(r)$. We note $\set{L}
    \quasiconst \set{Z}$ for the set of quasi-constant functions from \set{L}
    to \set{Z}.
  \item \textbf{Values} denotes the set of values in the language.
  \item \textbf{Types} denotes the set of values in the language.
  \item $\undef$ is a distinguished constant that represents an undefined
    field.
\end{itemize}

(in this formalism, the constant $\undef$ was called $\bot$, we renamed it here
in order to avoid confusion with the type $\bot$ representing an undefined
computation).

\subsection{Adaptation to a call-by-name semantic}

As long as we do not allow anything but constant strings as labels, this
formalism requires only a few modifications in order to be useful in a CBN
setting. In fact it is sufficient (I think) to interpret a record as an element
of $\ty{string} \quasiconst \textbf{Expressions} \cup \undef$ (instead of
$\ty{string} \quasiconst \textbf{Values} \cup \undef$).

\section{Dynamic labels}

In nix, the labels can be not only static strings, but also arbitrary
expressions (whose value can't by consequence be statically known in the
general case), which makes the typing more complicated and way less accurate.

One problem raised by this is the semantic of labels evaluation (ie: when do we
evaluate the labels ?). When the labels were static, this wasn't a problem at
all as evaluation of labels was a no-op

The most logical choice seems to evaluate every label eagerly as soon as we
need the value of one of them. This entails that record values will have the
form \texttt{\bfseries \{ $l$ = $e$; \ldots{}; $l$ = $e$; \}} where $l$ designs
an evaluated label (a string value). The semantic is then the one given in the
related \texttt{semantics} paper.

The consequence is that, for example, an ill-formed record (with a field
defined twice) won't be detected until it is used (one try to access or test
the existence of one of the fields), while with static fields the bad formation
of the record can be detected at the time of the definition, even in a lazy
setting.

Nix mixes both approaches by detecting a collision between static fields at
definition place and between dynamic fields (or between a static and a dynamic
one) at use-time. This approach is rather inconsistent (even more if we decide
to consider a static label $l$ as syntactic sugar for the dynamic label whose
expression is the constant string ``$l$''), so probably won't be reflected in
the type system\footnote{It could nonethless be implemented as a pre-treatment
of the AST in order to match nix's behaviour}.

\section{Orthogonal merge}

In CDuce, as in perl6 (the contexts into which respectivly~\cite{Fri04}
and~\cite{Cas15} have been written), a record can be defined with the same field
appearing twice, in which case the second appearance takes precedence over the
first. This led to the definition of the $\oplus_t$ (\emph{merge} with
respect to the value $t$) operator between two records.

In nix, such a definition would be invalid − the language require all
fields to be distinct − so we can't use this $\oplus_t$ operator to
define records and their typing.
We thus define a $\orthsum_t$ (orthogonal merge) operator defined as~:

if $r_1 = \{ l_1 = v_1; \ldots{}; l_n = v_n; \_ = v; \}$ \\
and $r_2 = \{ k_1 = w_1; \ldots{}; k_m = w_m; \_ = w; \}$
then
\[
  r_1 \orthsum_z r_2 =
  \begin{cases}
    r_1 \oplus_z r_2
      & \quad \text{if } v = w = z \text{\ and }
      \forall_{(i,j) \in \{1, \ldots{}, n \} x \{1, \ldots{}, m \}},
        l_i \neq k_j \\
    \bot & \quad \text{otherwise}
  \end{cases}
\].

We allow us to write $x \orthsum_z y$ as a shorthand for ``$x \orthsum_z y$ is
well-defined''.

In this case, the litteral expression

\begin{lstlisting}
{
    x1 = e1;
    ...;
    xn = en;
}
\end{lstlisting}

is syntactic sugar for

\begin{lstlisting}
{ x1 = e1; } (*$\orthsum_\undef$*) ... (*$\orthsum_\undef$*) { xn = en; }
\end{lstlisting}

\section{Typing}
\subsection{Static labels}

\begin{mathpar}
  \inferrule{%
      \Γ \vdash e : \τ
  }{%
    \Γ \vdash \{ l = e \} : \{ l: \τ \}
  }
  \and
  \inferrule{%
    \Γ \vdash e_1 : \τ_1 \\ \Γ \vdash e_2 : \τ_2 \\ \τ_1 \orthsum_\undef \τ_2
  }{%
    \Γ \vdash e_1 \orthsum_\undef e_2 : \τ_1 \orthsum_\undef \τ_2
  }
\end{mathpar}

\bibliographystyle{alpha}
\bibliography{../references}
\end{document}
